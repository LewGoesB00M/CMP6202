% -------------------------------------------------------------------------------
% Establish page structure & font.
\documentclass[12pt]{report}

\usepackage[total={6.5in, 9in},
	left=1in,
	right=1in,
	top=1in,
	bottom=1in,]{geometry} % Page structure

\usepackage{graphicx} % Required for inserting images
\graphicspath{{images/}} % Any additional images I use (BCU logo, etc) are from here.

\usepackage[utf8]{inputenc} % UTF-8 encoding
\usepackage[T1]{fontenc} % T1 font
\usepackage{float}  % Allows for floats to be positioned using [H], which correctly
                    % positions them relative to their location within my LaTeX code.
\usepackage{subcaption}

% -------------------------------------------------------------------------------
% Declare biblatex with custom Harvard BCU styling for referencing.
\usepackage[
    useprefix=true,
    maxcitenames=3,
    maxbibnames=99,
    style=authoryear,
    dashed=false, 
    natbib=true,
    url=false,
    backend=biber
]{biblatex}

% Additional styling options to ensure Harvard referencing format.
\renewbibmacro*{volume+number+eid}{
    \printfield{volume}
    \setunit*{\addnbspace}
    \printfield{number}
    \setunit{\addcomma\space}
    \printfield{eid}}
\DeclareFieldFormat[article]{number}{\mkbibparens{#1}}

% Declare it as the bibliography source, to be called later via \printbibliography
\addbibresource{Report.bib}

% -------------------------------------------------------------------------------
% To prevent "Chapter N" display for each chapter
\usepackage[compact]{titlesec}
\usepackage{wasysym}
\usepackage{import}

\titlespacing*{\chapter}{0pt}{-2cm}{0.5cm}
\titleformat{\chapter}[display]
{\normalfont\bfseries}{}{0pt}{\Huge}

% -------------------------------------------------------------------------------
% Custom macro to make an un-numbered footnote.

\newcommand\blfootnote[1]{
    \begingroup
    \renewcommand\thefootnote{}\footnote{#1}
    \addtocounter{footnote}{-1}
    \endgroup
}

% -------------------------------------------------------------------------------
% Fancy headers; used to show my name, BCU logo and current chapter for the page.
\usepackage{fancyhdr}
\usepackage{calc}
\pagestyle{fancy}

\setlength\headheight{37pt} % Set custom header height to fit the image.

\renewcommand{\chaptermark}[1]{%
    \markboth{#1}{}} % Include chapter name.


% Lewis Higgins - ID 22133848           [BCU LOGO]                [CHAPTER NAME]
\lhead{Lewis Higgins - ID 22133848~~~~~~~~~~~~~~~\includegraphics[width=1.75cm]{BCU}}
\fancyhead[R]{\leftmark}

% ------------------------------------------------------------------------------
% Used to add PDF hyperlinks for figures and the contents page.

\usepackage{hyperref}

\hypersetup{
    colorlinks=true,
    linkcolor=black,
    filecolor=magenta,
    urlcolor=blue,
    citecolor=black,
}

% ------------------------------------------------------------------------------
\usepackage{xcolor} 
\usepackage{colortbl}
\usepackage{longtable}
\usepackage{amssymb}
% ------------------------------------------------------------------------------
\usepackage{tcolorbox}
\newcommand{\para}{\vspace{8pt}\noindent}

% -------------------------------------------------------------------------------

\title{Using supervised learning for the binary classification of Type 2 Diabetes}
\author{Lewis Higgins - Student ID 22133848}
\date{December 2024}

% -------------------------------------------------------------------------------

\begin{document}


\makeatletter
\begin{titlepage}
    \begin{center}
        \includegraphics[width=0.7\linewidth]{BCU}\\[4ex]
        {\huge \bfseries  \@title}\\[50ex]
        {\@author}\\[2ex]
        {CMP6202 - Artificial Intelligence \& Machine Learning}\\[2ex]
        {Module Coordinator: Nouh Elmitwally}\\[10ex]
    \end{center}
\end{titlepage}
\makeatother
\thispagestyle{empty}
\newpage


% Page counter trick so that the contents page doesn't increment it.
\setcounter{page}{0}


\tableofcontents
\thispagestyle{empty}

\pagecolor{yellow}
\begin{abstract}
    Probably would benefit from an abstract. You can't really write this until the very end though,
    so return to it then. \textbf{The example work is from a previous year wherein this assessment was a group task.
    You can see that each group member developed one ML model, but you seem to be developing all of them yourself, so don't be mislead
    by the report titles only mentioning one model.}
\end{abstract}
\pagecolor{white}



Your EDA can be very extensive, and you could potentially have pages and pages and pages of it; this isn't a bad thing.
The vast majority of any ML-related work is EDA because it gives you the background information on the dataset to then apply
when training the model, such as the identification of non-numerical columns and encoding them into numerical equivalents where
possible so that they become useful training data for the model, as ML models cannot interpret strings.

\chapter*{Notes, remove before final}
\section{Mihai W7}
\subsection{Overall notes - Beginning of talk}
\begin{itemize}
    \item Find a problem before a dataset (No)
    \item Identify if said problem is regression or classification
    \item It's hard to use a classification dataset where the target column is just a bunch of labels (???)
    \begin{itemize}
        \item This may be in reference to Week 7's wine set where you had 7 different levels of quality but converted them to 2 for binary classification.
    \end{itemize}
    \item Examples on Moodle
    \item Datasets on Moodle but it's almost 100\% that someone else will have used them.
    \item I also don't know if you're even allowed to use them.
    \item A dataset can have more than one target column (though the ones you use likely won't).
    \item Mihai strongly warns that ML is a very iterative process, and your first attempt will probably be poor. \begin{itemize}
        \item This is why you use \textbf{pipelines} as in CMP6230 but that's not this module.
    \end{itemize}
    \item You will be asked questions on it in the presentation \textbf{RELATED TO WHAT YOU'VE DONE IN CLASS}, likely
    by Mihai himself, and he is trying to catch you out.
\end{itemize}

\subsection{Section 2}
\begin{itemize}
    \item After you have an identified dataset, begin EDA.
    \item Describe how you split the dataset into training and testing dataset.
    \item If the machine sees the test data, it may "overfit". \begin{itemize}
        \item You've seen this before where the line of best fit isn't really a line and just connects every single point, meaning it's 
        really good at guessing the data it already knows but not new data. 
    \end{itemize}
    \item You split your data \textit{BEFORE} EDA to avoid "conceptual overfitting".
    \item When splitting data, you need to think about data imbalance i.e. training set having too much of the one option and few of the other (too many True, not enough False).
    \item SKLearn may try to fix that for you.
    \item Identify outliers, missing data.
    \item "Missing information can be information in itself". Consider the source of the data (not Kaggle but rather where the Kaggle author got it from)
    \begin{itemize}
        \item You might be able to impute data rather than deleting it.
        \item Conserve as much data as you can, deleting data should be a last option.
    \end{itemize}
    \item Erroneous data \begin{itemize}
        \item Another reason why your data source is important.
        \item Could just be mistyped, see what the erroneous data actually is to see if you can correct it.
    \end{itemize}
    \item Outliers
    \begin{itemize}
        \item Is it significant enough to remove it? Is it definitely an outlier; could it feasibly be true? (speed camera example where one guy went 30 but another went 100, but that's still plausible.)
        \item Boxplots can identify outliers.
    \end{itemize}
    \item If your dataset is bad, your model will be, too.
\end{itemize}

\subsection{Section 3}
\begin{itemize}
    \item Identify the right algorithm. \begin{itemize}
        \item Decision trees are good at classification.
        \item Random forest is also used for it.
        \item Naive Bayes and KNN work for prediction and classification.
        \item Some of these may perform worse with higher amounts of data, look into them.
    \end{itemize}
    \item Performance won't matter a massive amount but you still need to be able to justify why it was good.
    \begin{itemize}
        \item Also justify its downsides and limitations.
        \item And the limtiations of the dataset itself.
    \end{itemize}
\end{itemize}

\subsection{Section 4}
\begin{itemize}
    \item Encoding is important here because ML doesn't use text. \begin{itemize}
        \item Side-note: Even if it does that's actually just an abstraction and it's just encoding it under the hood.
    \end{itemize}
    \item Fine-tuning \begin{itemize}
        \item Playing around with parameters of the functions.
        \item KNN Neighbours and such
        \item Often comes after an initial test run
        \item If your accuracy is really low (20\% was the example), fine-tuning won't help and you just need to redo the entire work.
        \item Could maybe give you an extra 5\% accuracy.
        \item Decision trees may have multiple versions. SKLearn's decision tree may be different from a CUDA one.
    \end{itemize}

    \item Evaluation metrics
    \begin{itemize}
        \item Accuracy is not Precision. Which do you need?
        \item You want both to be high, if one lags massively behind the other then that's bad.
        \item ML is an iterative process until you can get the best performing model.
    \end{itemize}
\end{itemize}

\subsection{Section 5}
    \begin{itemize}
        \item Visualisation of evaluation results
        \begin{itemize}
            \item For a correlation matrix, a heatmap is better than a bar plot for example.
        \end{itemize}
    \end{itemize}

% Cite some academic papers to prove you're making a good case. Mihai used the 
% term "literature review", so maybe he really does mean to that depth.

% Furthermore, while it may not actually be marked, describe everything you do within the Jupyter notebook with 
% Markdown text cells. It won't count to the word count and might let you sneak in some added detail that might not 
% have been able to go in the report.

\chapter{Introduction}

% You've opened by talking about the UK but then transitioned to the whole world?
% Your datasets are American and German in origin, so it's likely that the worldwide perspective will be better.
Diabetes mellitus, or type 2 diabetes, accounts for 90\% of the 4.4 million cases of diabetes in the UK, and it is estimated that 
there are 1.2 million undiagnosed cases of type 2 diabetes across the country \autocite{diabetes_uk_how_nodate}. The rate of type 
2 diabetes per 100,000 individuals is rapidly increasing, with \textcite{khan_epidemiology_2020}'s analysis projecting that by 
2030, the rate will reach 7,079 per 100,000. Many people with diabetes suffer immensely reduced quality of life, with approximately 50\% 
of patients suffering from peripheral neuropathy \autocite{dhanapalaratnam_effect_2024}, an irreversible disability which causes immense pain due 
to nerve damage from high blood sugar \autocite{nhs_peripheral_2022}, which can occur when the patient was unaware they even 
had diabetes. 

\para
Therefore, it is imperative that systems are put in place to enable the swift diagnosis of diabetes, especially type 2 diabetes 
given its major prevalence. This can be accomplished by training machine learning models on existing clinical datasets 
to identify common trends in those with and without type 2 diabetes. This report will document the planning, development 
and evaluation of multiple machine learning models in their classification of whether individuals have type 2 diabetes based 
on multiple clinical factors, specifically through the stages of:

\begin{itemize}
    \item Dataset Identification
    \item Data Integration
    \item Data Preprocessing
    \item Exploratory Data Analysis (EDA)
    \item Model Development 
    \item Model Evaluation
    \item Research Conclusions
\end{itemize}

\pagebreak 
\section{Dataset Identification}

Machine learning models require large amounts of data to train upon, meaning a dataset must be identified consisting of many 
rows and features. This project identified two datasets which could be integrated into one larger dataset, the first of which being 
the well-reputed Pima Indian\footnote{"Pima Indian" refers to a specific Native American ethnic group rather than people from India.} 
Diabetes Database \autocite{uci_machine_learning_pima_nodate}, sourced from \href{https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database}{Kaggle}, 
a platform for students and researchers alike to download and upload datasets and code for research purposes. The dataset contains data on Pima Indian women in 
Phoenix, Arizona, USA, and has previously seen wide use across academic literature relating to machine learning (\textcite{alzubi_diabetes_2023}, \textcite{zou_construction_2024}, \textcite{joshi_predicting_2021}, \textcite{hayashi_rule_2016}),
where other researchers have also aimed to solve the problem of diabetes classification via supervised learning. This dataset contains 768 rows with 9 features.
% Also cite Kaggle here rather than just hyperlinking it.

\para
This project also includes a second dataset, also from \href{https://www.kaggle.com/datasets/johndasilva/diabetes/data}{Kaggle}, that has been previously used in literature by 
\textcite{zou_construction_2024}. This dataset \autocite{john_dasilva_frankfurt_nodate} is based on data from female patients in Frankfurt, Germany, and includes the same 9 features as the Pima Indian dataset, but includes 2000 rows. By integrating these two datasets into one larger
dataset of 2768 rows, it will be possible to give the machine learning models more data to train upon.

\para Table \ref{tab:Features} details the 9 features seen in both datasets and their descriptions.
% You also need to include their types. Ordinal, nominal, etc as with CMP6230.

\begin{longtable}{ | p{0.3\textwidth} | p{0.5\textwidth} | }
    \hline
    \cellcolor{blue!25}Feature & \cellcolor{blue!25}Description \\
    \hline
    Pregnancies & The number of pregnancies the patient has had. \\
    \hline
    Glucose & Plasma glucose concentration over 2 hours in an oral glucose tolerance test. \\
    \hline
    BloodPressure & Diastolic blood pressure in mm/Hg. \\
    \hline
    SkinThickness & Triceps skin fold thickness (mm) \\
    \hline
    Insulin & 2-hour serum insulin. \\
    \hline
    BMI & Body Mass Index, calculated from the patient's weight and height. \\
    \hline
    DiabetesPedigreeFunction & The product of a function to ascertain the probability of diabetes based on family genetics. \autocite{akmese_diagnosing_2022} \\
    \hline
    Age & The patient's age.\\
    \hline
    Outcome & Whether the patient is likely to develop diabetes.\\
    \hline 
    \caption{The features seen in both datasets.}\label{tab:Features}
\end{longtable}

% An interesting statement was made by Mihai in Week 7.
% He said "You split your data BEFORE EDA to avoid conceptual overfitting".
% This probably should have been considered in the presentation slides.
% The template also is structured in a way where you split before analysis.

\section{Supervised learning task identification}
As previously mentioned, it is possible for patients to have diabetes without knowing. Therefore,
it is paramount that swift and simple diagnosis methods are put in place, which can be achieved 
through the use of supervised learning classification models. This requires the existence of the 
"ground truth", which refers to the label given to data that indicates its class \autocite{c3ai_what_nodate}. 
Within these datasets, the ground truth is present as the 'Outcome' feature, which will be used 
as the target variable for the produced classification models.
% Write more.


\chapter{Exploratory Data Analysis}
This chapter details the EDA processes undertaken with the datasets, including 
key questions that will be answered by the process, as well as the splitting of the 
data into training, testing % and validation
sets.

\section{Question identification}
% What questions do you have that thorough EDA would answer?
The key factors involved in the diagnosis of diabetes are critical to understand, which 
can be solved through EDA on these datasets. 
% Example A gives a good example on what this section should look like.

\section{Data Integration}
% Not included in template but I feel it's necessary to include somewhere.
The two datasets must first be merged into one to allow for an overall analysis to be performed.
This is a simple process because they both contain the same 9 features, and is detailed in Figure 
\ref{fig:Integration}.


\section{Splitting the dataset}
% How was the data split?
% Train/test? KFold?
% Training and testing sets are a minimum. It's possible they also want a VALIDATION set.

\section{EDA process and results}

% Screenshots work for the code but maybe Minted could be good.

\section{EDA conclusions}


\chapter{Experimental Design} % This may benefit from being its own .TeX file.
This chapter details the planned algorithms to be leveraged against this dataset,
as well as the metrics to evaluate them. Furthermore, the data cleaning and preprocessing 
stages will be deeply explored, as well as some potential limitations relating to their use.

\section{Identification of chosen algorithms}
% What algorithms? 
% Why those? 
% How do those algorithms work?


\section{Identification of appropriate evaluation techniques}
% What metrics?
% Why those?
% How do they show the model's performance?

\section{Data Cleaning and Pre-processing Transformations}
% What data cleaning techniques did you apply and why?
% Discuss:
%   What is data cleaning? (e.g. handling missing data)
%   What is data encoding? (label, one-hot)
%   What is data scaling? Why is it done?
%   Have any further engineering techniques been applied? Dimensionality reduction? <- research this
%   How have you handled missing data? (Imputation via KNNImputer as Zou et al. did?)

\section{Limitations and Options}
% What are the limitations of this approach?
%   The sheer amount of missing insulin data and imputation means the datasets are basically synthetic now.


\chapter{Model Development} % Titled "predictive modelling / model development" in template.
% This may benefit from being its own .TeX file.
This chapter details the training and evaluation processes of the original produced models
before any iterative improvements such as hyperparameter tuning.

\section{Predictive modelling process}
% What processes did you undertake to train the models?
%   How did you use the pre-processed data for training?
%   What parameters did you use?
%   Screenshots of code or Minted code blocks necessary.

\section{Results on seen data}
% Discuss evaluating your model on previously seen data i.e. the training set.
% Screenshots of code or Minted code blocks necessary.

\chapter{Evaluation and further improvements}
This chapter details the extensive evaluation of each model, as well as iterative improvements 
that were made to enhance their performance.
% This chapter MUST be its own .TeX file, and is the bulk of this report at first glance.
% No idea what this section entails, as the template is quite non-descript on it. (or over-descript idk)
% I believe it's about the iterative improvements to the models?


\chapter{Conclusion}
\section{Summary of results} 
% You've done this in labs, make a DF of all models and accuracies, plot it on a graph.
% Discuss the evaluation results for your final models.
% Summarise the entire report:
%   The problem
%   The datasets
%   Your methodology
%   Your results
%   Any insights gained?

\section{Reflection on Individual Learning}
% Nouh has previously stated he will begin here. This section could be 10% of the marks.
% What did you learn by doing this assignment?
% What aspects of the assignment did you enjoy most?
% How will you further hone your skills in future?

% You need evidence for this section. Miscellaneous certificates as well as public Github repositories.

\printbibliography

\end{document}